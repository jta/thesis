\section{Dataset}
\label{section:malawi:dataset}

This section provides an overview of the datasets used in this work and some of the data processing required before approaching the longitudinal study of Internet traffic rate limiting. 
The dataset used is composed from the original, un-anonymised traffic \acs{MAWI} \cite{mawi} traces, a set of daily packet captures from the \acs{WIDE} backbone network which provides connectivity to universities and research institutes in Japan. 
Traffic is collected daily for 15 minutes starting at 14:00 \acs{JST}. 
Although this dataset extends back largely uninterrupted from late 2001, the present work focuses on just over five years of data following a network upgrade to the monitored link on October 2006.
The monitored link carries mostly trans-Pacific commodity traffic between \acs{WIDE} customers and non-Japanese commercial networks. 
Traffic towards \acs{WIDE} is referred to as \emph{inbound} traffic, whereas traffic originating from within \acs{WIDE} is referred to as \emph{outbound} traffic.

\begin{table}[!htp]
\footnotesize
\centering
\ra{1.2}
    \input{data/malawi/summaryheader.tex}
    \input{data/malawi/summarydata.tex}
    \bottomrule
    \end{tabular}
    \caption{\label{table:overview}Overview of traced \acs{MAWI} dataset 
}
\vspace{-3mm}
\end{table}

A preliminary overview of the dataset used is provided in table \ref{table:overview}. 
In total, 5.7 billion flows containing data are traced over five largely uninterrupted years; this represents approximately 30 terabytes of \ac{TCP} traffic. For the purposes of this work, most analysis will focus on inbound traffic, 60\% to 80\% of which originates from port 80, referring only to analysis of outbound traffic when contextualizing findings.
Given the sender side plays a critical role in shaping traffic, analysing traffic for which the source is restricted to a small set of networks within Japan is of limited use in accurately depicting traffic trends at large.
Hosts within Japan are instead fixed as traffic sinks, thus sharing a similar perspective on inbound traffic as many other similarly sized networks. 

\subsection{Tracing \acs{TCP} Metrics}

All \ac{TCP} flows are reassembled and analysed for each daily trace.
In addition to the five tuple used to define each connection, two additional restrictions are imposed: a contiguous sequence number space and a three minute timeout. 
These restrictions are helpful to deal with port reuse and unterminated flows respectively.  
Although the total number of \ac{TCP} flows increased dramatically in 2011, the number of flows \emph{for which data payload was observed} has remained stable, averaging over 100 million data flows traced per year.  

There is much prior work with regards to reconstructing \ac{TCP} flow from passive measurements and using this information to understand the end-to-end properties of traffic \cite{firstRTT,Jaiswal:2007p233,Rewaskar:2007p195,Shakkottai:2004p408}. 
However, the \acs{MAWI} traces impose two constraints which require careful consideration, and ultimately led to the use of a custom \ac{TCP} tracer. 
The first one is the proportion of bidirectional flows, where both forward and reverse path are seen. 
In the dataset used this fluctuates between 40\% and 60\% over five years.
Most available \ac{TCP} tracers either ignore or are inadequate at processing unidirectional flows. 
The second one is the short duration of each individual trace file. 
At only 15 minutes of line-rate data capture per day, it is wasteful to ignore flows which are not complete. 
Although the number of flows for which a SYN and FIN in either direction is observed has remained consistently high until late 2011, these flows are normally \emph{mice}, i.e. flows that tend to be brief and which carry little traffic individually. 
In contrast, most \emph{elephants} (flows that carry significant traffic individually) have durations that exceed that of each trace file. 

Loss is inferred by accounting for \emph{retransmissions} in the upstream data and \emph{out-of-order packets} in downstream data; for the remainder of the paper the term \emph{end-to-end loss} will refer to the sum of out-of-order and retransmitted data bytes over the total data bytes in a given direction.
Anecdotally, this was found to be an adequate indicator of loss --- with the exception of \emph{hanging} \ac{TCP} connections. 
In such cases where connectivity is lost, a host will proceed to retransmit packets while performing an exponential back-off. 
Although this results in negligible overall traffic, it can significantly skew the inferred loss ratio for uncommon destinations for which little traffic exists. 
To account for these cases, a 3-second timeout on retransmissions was imposed, after which the congestion feedback loop to deemed to be broken. 

Each daily trace in the dataset is processed from a packet level capture into a collection of flow level statistics, providing insight into the end-to-end characteristics of traffic. 
However, since a core objective of this work is to augment this time-based information with data describing the endpoints of each flow, aggregating by location is also required. 

\subsection{Aggregating by Location}

Location information is added by mapping the original source and destination \ac{IP} addresses to its geographical and topological counterpoints. 
The routeviews archives \cite{routeviews} are used to reconstruct the mapping between each \ac{IP} and both \ac{AS} and network prefix; bi-hourly dumps of \ac{BGP} \acp{RIB} are available in the \acs{WIDE} archives since mid 2003. 
A daily \ac{RIB} is reconstructed based on the views provided by contributing \acp{AS}, in particular \ac{IIJ} and \ac{APNIC}.
Since exact routes are not disclosed (there is no record of local policy), there is no prior knowledge of the route taken by packets; this however does not hinder the ability to consistently map \acp{IP} to \acp{AS}.
While discrepancies in \ac{AS} destinations exist between different routeviews contributors, this happens almost exclusively on prefixes for which no actual traffic is seen. 

Mapping \ac{IP} to country is done through the use of GeoLite \cite{maxmind}, a commercial geolocation database. 
While the accuracy of this solution is often disputed, locating traffic at a fine granularity is not a pressing concern.
Most geographic emphasis will be placed on capturing macroscopic shifts in time at a national level, for which Geolite proves adequate.
The archive for geolocation data only extends to 2009, before which the earliest match must be used.
Additionally, the administrative mapping up until mid 2009 for a destination or source \ac{AS} is verified to have remained the same in the relevant \ac{RIR} archives in order for a flow to be assigned a geographical location.
% bridging paragraphs to save space.
After associating flows to country, region, \ac{AS} and network prefix for both source and destination \acp{IP}, flow statistics are aggregated over each location identifier. 
This generates a daily collection of location identifiers and associated flow properties, from which the geographic and topological properties of the dataset can be sketched over time.
