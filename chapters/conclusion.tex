\chapter{Conclusions}
\label{chapter:conclusions}

The presented body of work identifies opportunities and explores strategies for resource pooling through the application of \emph{re-feedback}.
Resource pooling has evolved to being performed by different stakeholders unilaterally: end-hosts, network operators and content providers all attempt to pool traffic by differing means, and in a potentially conflicting manner.
While recent work \cite{Kelly:2005p140,Wischik:2008p137,Wischik:2011p540} has lent credence to pushing resource pooling towards the edge, this ultimately ignores the tussle over how traffic is managed between these stakeholders.
Network operators attempt to exploit path diversity through a combination of route optimization and traffic balancing.
Collectively, these traffic engineering methods assist networks in minimizing the costs incurred by shifting traffic.
Conversely, hosts are increasingly capable of pooling traffic across paths either through the use of overlay networks or multipath congestion control, neither of which necessarily share the objectives of the underlying network.

The ultimate end-product of this thesis is INFLEX, a cross-layer architecture for resource pooling.
The proposed traffic management solution is based on extensive measurement data, easily deployable, and elegant, incurring no significant overhead at end-hosts and requiring limited, scalable processing within the network.
Importantly, it addresses concerns which are relevant to operators and users alike, and is shown to be:

\renewcommand{\descriptionlabel}[1]{\hspace{\labelsep}\textbf{#1}}
\begin{description}
\item[Efficient] through the application of congestion balancing. 
A model is derived for traffic assignment across different paths in proportion to the amount of congestion incurred by ongoing flows. 
In contrast to past efforts, this allows the network to balance traffic according to end-to-end loss. 
The resulting system is shown to make better use of available end-to-end capacity than existing methods traditionally applied by operators for traffic engineering purposes.
\item[Flexible] through the use of cross-layer signalling. 
\emph{Path re-feedback} in particular allows varying degrees of control by the network over how traffic is assigned to links while minimizing required state. Likewise, hosts are afforded path diversity but are free to opt out at no cost. 
This contrasts positively with existing solutions such as \ac{MPTCP}, where path setup can incur additional bandwidth and latency.
%TE, opt-out
\item[Robust] through the delegation of fault detection to hosts. 
The transport protocol can request path changes on-demand, which explicitly signals end-to-end path faults to the network. 
This information can in turn be crowd-sourced from ongoing flows by the network and assist in fault location and reparation.
\end{description}


\section{Summary of contributions}

This section summarises the contributions of this thesis in light of the original problem statement:

\begin{quote}
\textit{
Given the nature of Internet traffic, how can the current architecture be realigned to facilitate resource pooling at both network and transport layers?
}
\end{quote}

\subsection{Internet traffic characterisation}

This thesis began by providing a broader context within which to frame the evolution of resource pooling.
Chapter \ref{chapter:resourcepooling} traces how successive waves of new stakeholders and novel applications have influenced and shaped the protocols and tools which form the Internet.
Importantly, this chapter highlights traffic management as an architectural afterthought, best understood as being driven by the nature of the traffic and available capacity at hand.

In order to inform the design of a resource pooling architecture, an extensive longitudinal study of Internet interdomain traffic was undertaken and documented in chapter \ref{chapter:malawi}.
The analysis of the \ac{MAWI} dataset characterized over five years of TCP traces in relation to where traffic flows. 
The resulting longitudinal snapshot, from a single transit link, corroborates previous findings \cite{Labovitz:2010p175} showing a shift in content distribution.
Of particular relevance to the present work was the increased consolidation of traffic across a smaller set of stakeholders, with the ten most popular \acp{AS} alone accounting for over 50\% of all traffic in either direction.
From an operator perspective, this allows ample opportunity for balancing traffic by manipulating a smaller set of traffic prefixes.

Section \ref{section:malawi:rtt} further presented a novel \ac{RTT} recovery mechanism based on cumulative histogram construction and peak detection which assisted in analysing how large-scale shifts in where traffic flows from has impacted end-to-end delay.
The results highlight that traffic downstream is moving further away from Japan as content is not only placed closer to consumers and bypasses the transit link entirely, but also moves eastwards within the United States.
Conversely, upstream traffic has moved closer as data is predominantly uploaded to the very same co-location centres and content providers from which data is retrieved.
Within the observed time frame, the average \ac{RTT} for inbound and outbound data has converged to approximately 200$ms$.

\ac{RTT} recovery is in turn used to scalably reconstruct and classify flow throughput behaviour in chapter \ref{chapter:rate}.
The main contribution of this thread of work is in providing a re-evaluation of commonly held assumptions regarding Internet flow rates.
This was done by systematically identifying artificial constraints to \ac{TCP} traffic throughput across three categories: \emph{application pacing}, \emph{host limiting} and \emph{receiver shaping}. 
The resulting analysis shows that flow rates are not typically dictated by \ac{TCP} congestion control alone, and has significant implications on how to reason about resource sharing in particular.
The findings equally confirm that \ac{TCP} throughput is mostly determined by the actions of the sender and that continuing \acl{OS} updates have progressively lifted many of the limitations inherent to socket buffer sizes. 
These changes have allowed smaller flows to increase throughput at a far higher rate than larger flows, which are more often than not affected by other mechanisms of traffic shaping.
This means that, although there is a correlation between flow volume in bytes and throughput, the relationship between the two is non-linear and has changed with time.

\subsection{Architectural contributions}

The problem statement singled out the network and transport layers as the point in the Internet architecture where the tussle surrounding traffic management is greatest.
At the hosts, \ac{TCP} is designed to saturate available bandwidth, making efficient use of the network.
Within the network, operators often attempt to minimize the maximal link utilization in order to contain costs and ensure some degree of \ac{QoS}.
Re-feedback was originally proposed by Briscoe et al.\ \cite{Briscoe:2005p346} and applied to the re-\ac{ECN} protocol \cite{Briscoe:2008p494}, which was put forward as a potential solution for resolving the contention surrounding resource sharing -- how capacity is shared end-to-end.
It was therefore naturally identified as a starting point for addressing the contention surrounding resource pooling -- how traffic is allocated amongst paths.

Chapter \ref{chapter:preflex} began by stripping down re-\ac{ECN} into a coarser, more practical method for \acf{LEX}.
Re-\ac{ECN} was designed to provide congestion accountability, allowing each domain to precisely quantify the congestion incurred by others.
Operators could then be expected to charge their providers according to congestion volume - a metric exposed by re-\ac{ECN}.
Exposing congestion in an accurate and enforceable manner however made an otherwise elegant mechanism complicated to deploy.
\ac{LEX} stripped down the functionality of re-\ac{ECN} to address a different problem.
\ac{LEX} transmits information on loss as viewed by the transport layer to network resources, allowing traffic engineering to be performed taking into account end-to-end path quality.
As such, \ac{LEX} requires neither congestion marking at bottleneck routers, nor traffic shaping policers at the edges.

The use of loss exposure was then complemented with \acf{PREF}, a cross-layer signalling mechanism between the transport and network layer, also presented in chapter \ref{chapter:preflex}.
\ac{PREF} offers the ability for the network to select and offer paths to hosts, thereby unlocking the path diversity which already exists at stub domains such as \acp{ISP}, \acp{CDN} and enterprise networks.
Within the self-imposed constraints of \ac{IPv4} deployability, the resulting mechanism is necessarily simple, but also shown to be surprisingly versatile.
%, enabling novel end-to-end traffic management techniques such as congestion balancing, presented in chapter \ref{chapter:cate}, and resilient path fail-over, presented in chapter \ref{chapter:inflex}
Historically, the \ac{PREF} field can be interpreted as a synthesis of the previously sanctioned uses for the same header space: neither strictly abiding by the thesis that end-hosts should independently determine their own type of service, nor aligning itself with the antithetical view that the network alone should establish differentiated services.

Finally, chapter \ref{chapter:inflex} refines these proposals in the context of \ac{SDN}.
Section \ref{section:inflex:design} grounded the design of INFLEX on the observations made in chapters \ref{chapter:malawi} and \ref{chapter:rate}.
In comparison to \ac{PREFLEX}, INFLEX addresses resilience explicitly and minimizes the occurrence of path switching due to the delay incurred by network processing.
Existing transport proposals such as \ac{SCTP} and \ac{MPTCP} provide resilience through precautionary establishment of multiple end-to-end paths.
For short flows, such set up costs can be prohibitive in terms of latency.
By design, INFLEX provides resilience at no additional cost to flows: hosts can simply request to change path in reaction to network events.

% generality of TCP
\subsection{Resource pooling enhancements}

Given the Internet architecture should not dictate the outcome of the tussle between end-host and network solutions for resource pooling, the proposed architectural additions attempt to make both aware of each other.
This enables novel end-to-end traffic management techniques which are not currently possible, requiring only sender-side modifications for immediate deployment.

Chapter \ref{chapter:cate} describes one possible extreme of the tussle, in which the network is entirely responsible for resource pooling.
A congestion balancer is derived in which \ac{PREFLEX} can reap many of the benefits of \ac{MPTCP} by balancing flowlets according to loss, but without the need for application changes.
Unlike most existing \ac{TE} methods, congestion balancing with \ac{PREFLEX} is designed to minimize the impact of route changes on the transport layer and as such is assessed by its impact on transport metrics rather than traffic aggregates.
The use of congestion balancing in the network is shown to not only lead to a more efficient use of network capacity, but also a reduction of flow completion times.

Chapter \ref{chapter:inflex} adopted the principles of path re-feedback to provide on-demand path fail-over for \ac{IP} traffic.
Under the current architecture, path failures are largely a network responsibility: operators are expected to detect, repair and recover from faults which may originate from beyond their network domain.
Detection often requires scale -- the reliability with which a fault can be identified relies on the proportion of traffic affected -- and in many cases faults affecting individual flows may go undetected.
Reparation varies according to the nature and origin of the fault, and is often not easily automated and itself error-prone.
In either case, the amount of time expended in detection and repair can often preclude recovery, since most flows will terminate after successive timeouts.

The presented solution for resilient traffic management, INFLEX, is both unilaterally deployable, providing benefits even when adopted by individual domains, and inherently end-to-end, potentially covering third party failures.
Since INFLEX operates as an extension to the network abstraction provided by \ac{IP}, it can be used by all transport protocols.
At the host, the proposed architecture allows transport protocols to switch network paths at a timescale which avoids flow disruption and which can be transparently integrated into existing congestion control mechanisms.
Within the network, INFLEX provides both greater insight into end-to-end path quality, assisting fault detection, and more control over flow path assignment, enabling more effective fault recovery. 
INFLEX was implemented and verified experimentally through modifications to both the \ac{TCP}/\ac{IP} network stack and a popular Openflow controller \cite{pox} and made publicly available.



\section{Future work}

While chapter \ref{chapter:inflex} ties most of the work of the previous chapters together, some threads remain outstanding.
The most immediate concern is that the current implementation of INFLEX validated in section \ref{section:inflex:eval} does not yet allow for congestion balancing, described in chapter \ref{chapter:cate}.
Most of the required changes are accounted for and described in detail in section \ref{section:inflex:discussion}.
In the longer term, this work has raised several higher-level issues which are outside the scope of this thesis and as such remain potential avenues for future work:

\renewcommand{\descriptionlabel}[1]{\hspace{\labelsep}\textbf{#1.}}
\begin{description}
\item[System stability]{
Concerns over route flapping were raised both in chapter \ref{chapter:cate} and \ref{chapter:inflex}.
With congestion balancing the time period between updates of the flow split ratio is paced according to the sparseness of loss, but chapter \ref{chapter:cate} falls short of providing either a formal proof for stability or extensive enough evaluation.
The changes introduced in chapter \ref{chapter:inflex} however are likely to significantly reduce the likelihood of route flapping, notwithstanding the limitations of Openflow raised in section \ref{section:inflex:discussion}.
Since in INFLEX resilience and efficiency are decoupled, an operator can afford to be more conservative in congestion balancing without forsaking responsiveness to failures.
Lagging system response in this manner does not affect an operator's primary objective in adopting congestion balancing: namely, keeping upstream providers in check over the quality-of-service they provide and distributing traffic accordingly.
}
\item[Quality-of-service]{
Due to its contentious nature, most of the work in this thesis meanders around the subject of \ac{QoS}.
The INFLEX architecture however provides a clear path of deployment for some degree of service differentiation.
The policy mechanisms described in section \ref{section:inflex:arch} allow operators to select which forwarding planes are exposed to individual hosts or flows.
Further integration with existing resource management tools within datacenters would allow such policies to be enforced by tenant.
Traditional approaches to \ac{QoS} typically rely on operators provisioning their networks according to preordained service types such as those requiring high throughput or low latency.
Within the design principles enunciated in chapter \ref{chapter:preflex}, a more reasonable solution would be to apply division of labour in providing \ac{QoS}.
Instead of normalising the expected loss rate over multiple paths as described in chapter \ref{chapter:cate}, an operator could instead adjust congestion balancing to provide differentiated tiers.
Hosts would then be responsible in assembling higher quality service from essentially parallel, best-effort forwarding planes according to their needs.
}


\item[Extending transport]{
A counter-intuitive result from chapter \ref{chapter:rate} is that \ac{TCP} is both becoming both increasingly ossified, with even minor \ac{TCP} extensions taking several years to deploy, and remarkably diverse, with applications asserting their own behaviour on how \ac{TCP} performs.
The legacy of middlebox support dictates that any new transport protocol will effectively be implemented over \acs{UDP} or as extensions to \ac{TCP} \cite{Honda11}, such as the \ac{MPTCP}.
Neither of these approaches however tackles how to gain sufficient critical mass to ensure timely deployment.
A clear line of future work is instead to push the transport stack up to user space, where the functionality provided can be tailored and potentially deployed alongside applications.
While past work has addressed this challenge \cite{Thekkath93,sctpuser}, there is no mature solution for providing user-level, backward-compatible protocol stacks which can saturate existing line rates. 
At present however there is both a technical foundation for such software, through work in fast packet \acs{I/O} mechanisms such as \emph{netmap} \cite{Rizzo12acmq}, and a practical need, as existing applications such as web caches attempt to scale beyond the performance afforded by general-purpose network stacks.
}
\end{description}

In pushing network state outwards to the end-host and exposing path diversity in the process, the \emph{re-feedback} mechanisms explored in this thesis can be applied in exploring all of the above.
The versatility of path re-feedback in particular stands as likely the single most valuable legacy of this work.
Compared to both the \ac{ToS} or \ac{DS} fields, it is in many ways a stronger ideological heir to the original design philosophy of the \acs{DARPA} internet protocols.
In deliberating on the success of the latter in \cite{Clark:1988p478}, Clark concludes by identifying shortcomings of the datagram model given requirements which had not originally been contemplated:

\begin{quote}
\textit{While the datagram has served very well in solving the most important goals of the Internet, it has not served so well when we attempt to address some of the goals which were further down the priority list. 
For example, the goals of resource management and accountability have proved difficult to achieve in the context of datagrams.
As the previous section discussed, most datagrams are a part of some sequence of packets from source to destination, rather than isolated units at the application level.  
However, the gateway cannot directly see the existence of this sequence, because it is forced to deal with each packet in isolation.  
Therefore, resource management decisions or accounting must be done on each packet separately.  
Imposing the datagram model on the internet layer has deprived that layer of an important source of information which it could use in achieving these goals.}
\end{quote}

In the intervening quarter of a century, progress in resource management and accountability has become predominantly driven by operators intent in coaxing existing practices from the telephone network.
Rather than assessing such mechanisms in terms of their impact on the evolution of the Internet, practices such as the maintenance of flow state within the network or the prescription of classes of service are instead often justified on technical feasibility alone.
For this reason, the long term ramifications of software-defined networking are particularly hard to discern given it offers a cleaner abstraction for layering and composing many new forms of network functionality -- some of which may add further complexity to the datagram model.
In establishing future research directions for retaining the inherent properties of the Internet while accommodating resource management in \cite{Clark:1988p478}, Clark concludes:

\begin{quote}
\textit{
It would be necessary for the gateways to have flow state in order to remember the nature of the flows which are passing through them, but the state information would not be critical in maintaining the desired type of service associated with the flow. Instead, that type of service would be enforced by the end points, which would periodically send messages to ensure that the proper type of service was being associated with the flow.
(...)
I call this concept ``soft state,'' and it may very well permit us to achieve our primary goals of survivability and flexibility, while at the same time doing a better job of dealing with the issue of resource management and accountability.
}
\end{quote}

This thesis went one step further, realising soft state as a workable technology rather than an architectural talking point and demonstrating its practicality through direct application to addressing existing requirements.
However, convincing a wider community that mechanisms such as path re-feedback can greatly simplify traffic management remains unrealized and arguably the most significant outstanding challenge within this work.
